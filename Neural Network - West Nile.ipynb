{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Implementation: West Nile in Chicago\n",
    "\n",
    "\n",
    "### Kaggle: West Nile\n",
    "\n",
    "The data set comes from a Kaggle competition where users were given data related to mosquito tests, weather, and mosquito spraying in the city of Chicago.\n",
    "\n",
    "For the case of this neural network implementation, I used my existing cleaned and combined data from the competition.\n",
    "\n",
    "### Neural Network: Keras & Theano\n",
    "\n",
    "For this implementation, I used [Keras](http://keras.io/), a wrapper which provides a Scikit-Learn style API for theano and tensorflow. I find keras provides a great framework for getting a neural net up and running quickly as well as several tools for cleaning and tweaking data. I used keras over theano, training on CPU - however theano does have the ability to train on a GPU using a Cuda backend.\n",
    "\n",
    "In this example, I used Keras's sequential model. The network has three dense layers of 32 perceptrons each with a 0.5 dropout rate (0.2 on the input layer) using the Rectifier Linear Unit (ReLU) activation function, then a 2 perceptron output layer with a SoftMax activation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependecies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#Pandas - dataframes and data management\n",
    "import pandas as pd\n",
    "\n",
    "#Theano / numPy - math and matrix operations\n",
    "import theano\n",
    "import numpy as np\n",
    "\n",
    "#Keras - Neural Net API\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "\n",
    "#Sklean - metric, preprocessing, cross-validation\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Train and Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10506, 37)\n",
      "(116293, 36)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./assets/trainComb.csv')\n",
    "test_data = pd.read_csv('./assets/testComb.csv')\n",
    "\n",
    "print train.shape\n",
    "print test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Keras Model\n",
    "\n",
    "#### Model: Sequential\n",
    "\n",
    "#### Input Layer\n",
    "\n",
    "#### Dense Layers\n",
    "\n",
    "#### Output Layer\n",
    "\n",
    "#### Loss\n",
    "\n",
    "#### Optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def annModel(inputD,outputD):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(32, input_dim=inputD))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(32, init='glorot_uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(32, init='glorot_uniform'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(outputD))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adadelta\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = [ u'Species', u'Latitude', u'Longitude',u'Week', u'Month', u'Tmax_x',\n",
    "       u'Tmin_x', u'Tavg_x', u'DewPoint_x', u'WetBulb_x',\n",
    "     u'StnPressure_x',]\n",
    "\n",
    "X = train[feature_cols]\n",
    "y = train['WnvPresent']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCAScale = Pipeline([('PCA',PCA(n_components=10)),('scale',StandardScaler())])\n",
    "# X = PCAScale.fit_transform(X)\n",
    "\n",
    "scale = StandardScaler()\n",
    "X = scale.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess target\n",
    "\n",
    "Our model is outputting two values: rows predicted 0, and rows predicted 1. I found this to improve the accuracy of the network as opposed to predicting a single output of 0 or 1\n",
    "\n",
    "Keras has a utlity which quickly takes a variable (WnvPresent) and formats it as a numpy array with a binary variable for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yc = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold Validation of Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold and model atributes\n",
    "\n",
    "5 folds, shuffled to prevent clumps of data, with a random state for consistency through model tweaks.\n",
    "\n",
    "Input dimensions: # of features\n",
    "Output dimensions: # of categories (2, 1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kf = KFold(len(y), n_folds=5 ,shuffle=True, random_state=0)\n",
    "inputD = X.shape[1]\n",
    "outputD = 2\n",
    "\n",
    "\n",
    "auc_scores = []\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KFold Cross-Val\n",
    "\n",
    "Runs the model 5 times, each time on a new set of training data holding out a portion of the data for validation. The model uses the validation data to optimize the loss function.\n",
    "\n",
    "#### Neural Net parameters:\n",
    "\n",
    "Epochs - 100\n",
    "Batch Size - 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Start 1\n",
      "Fold Score: 0.8068\n",
      "Fold Complete 1\n",
      "Fold Start 2\n",
      "Fold Score: 0.8280\n",
      "Fold Complete 2\n",
      "Fold Start 3\n",
      "Fold Score: 0.7962\n",
      "Fold Complete 3\n",
      "Fold Start 4\n",
      "Fold Score: 0.7713\n",
      "Fold Complete 4\n",
      "Fold Start 5\n",
      "Fold Score: 0.8246\n",
      "Fold Complete 5\n"
     ]
    }
   ],
   "source": [
    "for training, testing in kf:\n",
    "    fold += 1\n",
    "    print \"Fold Start\", fold\n",
    "    X_train = X[training]\n",
    "    X_test = X[testing]\n",
    "    y_train = yc[training]\n",
    "    y_test = yc[testing]\n",
    "    y_true = y[testing]\n",
    "\n",
    "    model = annModel(inputD,outputD)\n",
    "    model.fit(X_train, y_train, nb_epoch=100, batch_size=16, validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    y_probs = model.predict_proba(X_test,verbose=0)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    roc = metrics.roc_auc_score(y_test, y_probs)\n",
    "    auc_scores.append(roc)\n",
    "    print \"Fold Score: %.4f\" % roc\n",
    "    print \"Fold Complete\", fold\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local CV AUC Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean AUC Score:\n",
      "0.805375828195 \n",
      "\n",
      "Fold Scores:\n",
      "0.8068\n",
      "0.8280\n",
      "0.7962\n",
      "0.7713\n",
      "0.8246\n"
     ]
    }
   ],
   "source": [
    "print \"Mean AUC Score:\"\n",
    "print np.mean(auc_scores), '\\n'\n",
    "\n",
    "print \"Fold Scores:\"\n",
    "for a in auc_scores:\n",
    "    print \"%.4f\" % a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model on all of the data\n",
    "\n",
    "Increase the number of epochs as we're only running the model once, not 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11957ff10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputD = X.shape[1]\n",
    "outputD = 2\n",
    "\n",
    "model = annModel(inputD,outputD)\n",
    "model.fit(X, yc, nb_epoch=200, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test data, and make predictions using the trained neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Species</th>\n",
       "      <th>Trap</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>AddressAccuracy</th>\n",
       "      <th>Week</th>\n",
       "      <th>test_geo</th>\n",
       "      <th>Station</th>\n",
       "      <th>...</th>\n",
       "      <th>WetBulb</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Cool</th>\n",
       "      <th>SnowFall</th>\n",
       "      <th>PrecipTotal</th>\n",
       "      <th>StnPressure</th>\n",
       "      <th>SeaLevel</th>\n",
       "      <th>ResultSpeed</th>\n",
       "      <th>ResultDir</th>\n",
       "      <th>AvgSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>(41.95469,-87.800991)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.28</td>\n",
       "      <td>29.99</td>\n",
       "      <td>8.9</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>(41.95469,-87.800991)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.28</td>\n",
       "      <td>29.99</td>\n",
       "      <td>8.9</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>(41.95469,-87.800991)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.28</td>\n",
       "      <td>29.99</td>\n",
       "      <td>8.9</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>(41.95469,-87.800991)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.28</td>\n",
       "      <td>29.99</td>\n",
       "      <td>8.9</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008-06-11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>41.95469</td>\n",
       "      <td>-87.800991</td>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>(41.95469,-87.800991)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.28</td>\n",
       "      <td>29.99</td>\n",
       "      <td>8.9</td>\n",
       "      <td>18</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id        Date  Species  Trap  Latitude  Longitude  AddressAccuracy  Week  \\\n",
       "0   1  2008-06-11        2     1  41.95469 -87.800991                9    24   \n",
       "1   2  2008-06-11        3     1  41.95469 -87.800991                9    24   \n",
       "2   3  2008-06-11        1     1  41.95469 -87.800991                9    24   \n",
       "3   4  2008-06-11        4     1  41.95469 -87.800991                9    24   \n",
       "4   5  2008-06-11        6     1  41.95469 -87.800991                9    24   \n",
       "\n",
       "                test_geo  Station    ...     WetBulb  Heat  Cool  SnowFall  \\\n",
       "0  (41.95469,-87.800991)        1    ...        64.0   0.0   NaN         0   \n",
       "1  (41.95469,-87.800991)        1    ...        64.0   0.0   NaN         0   \n",
       "2  (41.95469,-87.800991)        1    ...        64.0   0.0   NaN         0   \n",
       "3  (41.95469,-87.800991)        1    ...        64.0   0.0   NaN         0   \n",
       "4  (41.95469,-87.800991)        1    ...        64.0   0.0   NaN         0   \n",
       "\n",
       "   PrecipTotal  StnPressure  SeaLevel  ResultSpeed  ResultDir  AvgSpeed  \n",
       "0          0.0        29.28     29.99          8.9         18      10.0  \n",
       "1          0.0        29.28     29.99          8.9         18      10.0  \n",
       "2          0.0        29.28     29.99          8.9         18      10.0  \n",
       "3          0.0        29.28     29.99          8.9         18      10.0  \n",
       "4          0.0        29.28     29.99          8.9         18      10.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xt = test_data[feature_cols]\n",
    "Xt = scale.fit_transform(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_probs = model.predict_proba(Xt,verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Kaggle Submission\n",
    "\n",
    "For this competition, Kaggle used AUC score as a leaderboard metric, so submissions were in the format of predicted probabilities for class 1 (WnvPressent == 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./assets/sampleSubmission.csv')\n",
    "subdat = pd.DataFrame(submission)\n",
    "\n",
    "subdat['WnvPresent'] = sub_probs[:,1]\n",
    "subdat.to_csv('test_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
